{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- timestamp: timestamp (nullable = true)\n",
      " |-- currentLocation: string (nullable = true)\n",
      " |-- participantId: integer (nullable = true)\n",
      " |-- currentMode: string (nullable = true)\n",
      " |-- hungerStatus: string (nullable = true)\n",
      " |-- sleepStatus: string (nullable = true)\n",
      " |-- apartmentId: integer (nullable = true)\n",
      " |-- availableBalance: float (nullable = true)\n",
      " |-- jobId: integer (nullable = true)\n",
      " |-- financialStatus: string (nullable = true)\n",
      " |-- dailyFoodBudget: float (nullable = true)\n",
      " |-- weeklyExtraBudget: float (nullable = true)\n",
      " |-- currentLocationX: float (nullable = true)\n",
      " |-- currentLocationY: float (nullable = true)\n",
      " |-- date: date (nullable = true)\n",
      "\n",
      "+-------------------+--------------------+-------------+-----------+------------+-----------+-----------+----------------+-----+---------------+---------------+-----------------+----------------+----------------+----------+\n",
      "|          timestamp|     currentLocation|participantId|currentMode|hungerStatus|sleepStatus|apartmentId|availableBalance|jobId|financialStatus|dailyFoodBudget|weeklyExtraBudget|currentLocationX|currentLocationY|      date|\n",
      "+-------------------+--------------------+-------------+-----------+------------+-----------+-----------+----------------+-----+---------------+---------------+-----------------+----------------+----------------+----------+\n",
      "|2022-03-01 00:00:00|POINT (-2724.6277...|            0|     AtHome|     JustAte|   Sleeping|        926|       1286.5195|  254|         Stable|           12.0|        1104.3026|      -2724.6277|        6866.208|2022-03-01|\n",
      "|2022-03-01 00:00:00|POINT (-1526.9372...|            1|     AtHome|     JustAte|   Sleeping|        928|        860.5742|  929|         Stable|           12.0|        926.71436|      -1526.9373|        5582.295|2022-03-01|\n",
      "+-------------------+--------------------+-------------+-----------+------------+-----------+-----------+----------------+-----+---------------+---------------+-----------------+----------------+----------------+----------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.types as types\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# df = spark.read.csv(\"./work/datasets/Activity Logs/\", header=True, schema=\"timestamp TIMESTAMP, currentLocation STRING, participantId INT, currentMode STRING, hungerStatus STRING, sleepStatus STRING, apartmentId INT, availableBalance FLOAT, jobId INT, financialStatus STRING, dailyFoodBudget FLOAT, weeklyExtraBudget DOUBLE\")\n",
    "df = spark.read.csv(\"./work/datasets/Activity Logs/\", header=True, schema=types.StructType([\n",
    "    types.StructField('timestamp', types.TimestampType()),\n",
    "    types.StructField('currentLocation', types.StringType()),\n",
    "    types.StructField('participantId', types.IntegerType()),\n",
    "    types.StructField('currentMode', types.StringType()),\n",
    "    types.StructField('hungerStatus', types.StringType()),\n",
    "    types.StructField('sleepStatus', types.StringType()),\n",
    "    types.StructField('apartmentId', types.IntegerType()),\n",
    "    types.StructField('availableBalance', types.FloatType()),\n",
    "    types.StructField('jobId', types.IntegerType()),\n",
    "    types.StructField('financialStatus', types.StringType()),\n",
    "    types.StructField('dailyFoodBudget', types.FloatType()),\n",
    "    types.StructField('weeklyExtraBudget', types.FloatType()),\n",
    "])).\\\n",
    "    withColumn('currentLocationX', F.regexp_extract('currentLocation', 'POINT \\(([^ ]+) ([^ ]+)\\)', 1).cast('float')).\\\n",
    "    withColumn('currentLocationY', F.regexp_extract('currentLocation', 'POINT \\(([^ ]+) ([^ ]+)\\)', 2).cast('float')).\\\n",
    "    withColumn('date', F.to_date('timestamp'))\n",
    "\n",
    "df.printSchema()\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.partitionBy('date').mode('overwrite').parquet(\"./work/tobi/parquet/activity_logs2.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
